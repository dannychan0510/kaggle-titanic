sumCoef[2,1] + c(-1, 1) * qt(.95, df = fit$df) * sumCoef[2, 2]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
dB <- as.data.frame(mtcars)
fit <- lm(mpg ~ I(wt/2), data = dB)
summary(fit)$coefficients
sumCoef <- summary(fit)$coefficients
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
?qt
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
summary(interceptOnly)
anova(interceptOnly)
anova(interceptOnly)[2]
anova(interceptAndSlope)[2] / anova(interceptOnly)[2]
anova(interceptAndSlope)[[2]] / anova(interceptOnly)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)[[2]]
anova(interceptAndSlope)
anova(interceptAndSlope)[[2, 1]]
anova(interceptAndSlope)[[1, 2]]
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[1, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)
anova(interceptOnly)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
dB <- as.data.frame(mtcars)
interceptOnly <- lm(mpg ~ 1, data = dB)
interceptAndSlope <- lm(mpg ~ wt, data = dB)
anova(interceptAndSlope)[[2, 2]] / anova(interceptOnly)[[2]]
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
hist(mns)
hist(runif(1000))
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(rexp(40, 5)))
hist(mns)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
library(ggplot2)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(1 : 6, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(1 : 6, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
View(dat)
nosim <- 1000
cfunc <- function(x, n) sqrt(n) * (mean(x) - 3.5) / 1.71
dat <- data.frame(
x = c(apply(matrix(sample(1 : 6, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(alpha = .20, binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
nosim <- 1000
cfunc <- function(x, n) 2 * sqrt(n) * (mean(x) - 0.5)
dat <- data.frame(
x = c(apply(matrix(sample(0:1, nosim * 10, replace = TRUE),
nosim), 1, cfunc, 10),
apply(matrix(sample(0:1, nosim * 20, replace = TRUE),
nosim), 1, cfunc, 20),
apply(matrix(sample(0:1, nosim * 30, replace = TRUE),
nosim), 1, cfunc, 30)
),
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
size = factor(rep(c(10, 20, 30), rep(nosim, 3))))
View(dat)
g <- ggplot(dat, aes(x = x, fill = size)) + geom_histogram(binwidth=.3, colour = "black", aes(y = ..density..))
g <- g + stat_function(fun = dnorm, size = 2)
g + facet_grid(. ~ size)
mns = NULL
for (i in 1 : 1000) mns = c(mns, mean(runif(40)))
mns
hist(mns)
mns = NULL
for (i in 1 : 1000) mns = c(mns, sd(runif(40)))
hist(mns)
data(sleep)
sleep <- sleep
View(sleep)
1100 + c(-1, 1) * qt(0.975, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30 / (9)^.4
1100 + c(-1, 1) * qt(0.95 / 2, 9 - 1) * 30 / (9)^.5
help qt
?qt
xbar <- 1100
sd <- 30
n <- 9
mean + c(-1, 1) * qt(0.95, n-1) * (sd / sqrt(n))
xbar <- 1100
sd <- 30
n <- 9
xbar + c(-1, 1) * qt(0.95, n-1) * (sd / sqrt(n))
xbar <- 1100
sd <- 30
n <- 9
xbar + c(-1, 1) * qt(0.975, n-1) * (sd / sqrt(n))
qt(0.975, 8)
xbar <- -2
n <- 9
xbar * sqrt(n) / qt(0.975, n-1)
xbar_old <- 3
sd_old <- 0.6
n_old <- 10
xbar_new <- 5
sd_new <- 0.68
n_new <- 10
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 3
sd_old <- 0.6
n_old <- 10
xbar_new <- 5
sd_new <- 0.68
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
sd_old <- 0.68
n_old <- 10
xbar_new <- 3
sd_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(n_new - n_old) + c(-1, 1) * qt(0.975 / 2, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
sd_old <- 0.68
n_old <- 10
xbar_new <- 3
sd_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old^2) + ((n_new - 1)*sd_new^2)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*sd_old) + ((n_new - 1)*sd_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 20
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) / sqrt((n_old) + (n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(n_new - n_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 5
var_old <- 0.68
n_old <- 10
xbar_new <- 3
var_new <- 0.6
n_new <- 10
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
(xbar_new - xbar_old) + c(-1, 1) * qt(0.95, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 6
var_old <- 2
n_old <- 100
xbar_new <- 4
var_new <- 0.5
n_new <- 100
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_new - xbar_old) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_old <- 6
var_old <- 2
n_old <- 100
xbar_new <- 4
var_new <- 0.5
n_new <- 100
pooled_var <- (((n_old - 1)*var_old) + ((n_new - 1)*var_new)) / (n_old + n_new - 2)
(xbar_old - xbar_new) + c(-1, 1) * qt(0.975, n_old + n_new - 2) * sqrt(pooled_var) * sqrt((1 / n_old) + (1 / n_new))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_placebo - xbar_treatment) + c(-1, 1) * qt(0.975, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_placebo - xbar_treatment) + c(-1, 1) * qt(0.95, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
xbar_placebo <- 1
var_placebo <- 1.8^2
n_placebo <- 9
xbar_treatment <- -3
var_treatment <- 1.5^2
n_treatment <- 9
pooled_var <- (((n_placebo - 1)*var_placebo) + ((n_treatment - 1)*var_treatment)) / (n_placebo + n_treatment - 2)
(xbar_treatment - xbar_placebo) + c(-1, 1) * qt(0.95, n_placebo + n_treatment - 2) * sqrt(pooled_var) * sqrt((1 / n_placebo) + (1 / n_treatment))
?power.t.test
week1 <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
t.test(week1, week2, alternative = "two.sided", paired = T)
week1 <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
t.test(week1, week2, alternative = "two.sided", paired = T)
m0 <- 1081
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1119
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1031
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1080
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
m0 <- 1077
power.t.test(n = 9, sd = 30, delta = m0 / 1100, type = "one.sample", alt = "one.sided")
n = 9; mu = 1100; sd=30
mu + c(-1,1) * qt(.975, n-1) * sd/sqrt(n)
n <- 9
m0 <- 1100
sd <- 30
m0 + c(-1, 1) * qt(.975, n - 1) * sd / sqrt(n)
binom.test(3, 4, alt= "greater")$p.value
?poisson.test
poisson.test(x = 10, T = 1787, r = 1/100, alternative = "less")$p.value
poisson.test(x = 10, T = 1787, r = 1/100, alternative = "less")
n <- 100 #subject
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- power.t.test(n=n, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$power
round(pow, 2)
μ <- 0.01# m^3 brain volume loss mean
σ <- 0.04# m^3 brain volume loss std. dev.
p <- 0.05 # sign level
pow <- 0.9 #power
n <- power.t.test(power=pow, delta=μ, sd=σ , sig.level=p, type="one.sample", alt="one.sided")$n
ceiling(n/10)*10
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
names(shuttle)
?glm
fit <- glm(use ~ wind, family='binomial', shuttle)
exp(fit$coeff)
fit <- glm(use ~ wind + as.factor(magn), family='binomial', shuttle)
exp(fit$coeff)
library(MASS)
head(shuttle)
shuttle2<-shuttle
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
#shuttle2$wind2<-as.numeric(shuttle2$wind=='head')
#head(shuttle2)
fit<-glm(use2 ~ factor(wind) - 1, family = binomial, data = shuttle2)
#0.03181
#fit<-glm(use ~ wind, family = binomial, data = shuttle)
#anova(fit)
summary(fit)$coef
fit<-glm(use2 ~ factor(wind) + factor(magn) - 1, family = binomial, data = shuttle2)
summary(fit)$coef
exp(coef(fit))
exp(cbind(OddsRatio = coef(fit), confint(fit)))
1.286 / 1.327
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data <- AlzheimerDisease
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
library(caret)
data("AlzheimerDisease")
library(ggplot)
library(ggplot2)
setwd("~/Documents/GitHub/kaggle-titanic")
library(ggplot2)
# Import data
genderclassmodel <- read.csv("Data\\genderclassmodel.csv", stringsAsFactors = FALSE)
gendermodel <- read.csv("Data\\gendermodel.csv", stringsAsFactors = FALSE)
test <- read.csv("Data\\test.csv")
train <- read.csv("Data\\train.csv")
genderclassmodel <- read.csv("Data/genderclassmodel.csv", stringsAsFactors = FALSE)
gendermodel <- read.csv("Data/gendermodel.csv", stringsAsFactors = FALSE)
genderclassmodel <- read.csv("Data/genderclassmodel.csv", stringsAsFactors = FALSE)
gendermodel <- read.csv("Data/gendermodel.csv", stringsAsFactors = FALSE)
test <- read.csv("Data/test.csv")
train <- read.csv("Data/train.csv")
# Creating a combined dataset with both training and test data
test$Survived <- NA
combi <- rbind(train, test)
# Changing name back to character
combi$Name <- as.character(combi$Name)
# Creating a Title variable from the Name variable
combi$Title <- sapply(combi$Name, FUN = function(x) {strsplit(x, split = '[,.]')[[1]][2]})
combi$TItle <- sub(' ', '', combi$Title)
# Combining a few of the unusual titles
combi$Title[(combi$Title %in% c('Mme', 'Mlle'))] <- 'Mlle'
combi$Title[(combi$Title %in% c('Capt', 'Don', 'Major', 'Sir'))] <- 'Sir'
combi$Title[(combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer'))] <- 'Lady'
# Changing the Title variable back into a factor variable
combi$Title <- factor(combi$Title)
# Creating a variable which captures the size of the family
combi$FamilySize <- combi$SibSp + combi$Parch + 1
# Creating a Surname variable
combi$Surname <- sapply(combi$Name, FUN = function(x) {strsplit(x, split = '[,.]')[[1]][1]})
# Combining the FamilySize and Surname varaiables
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep = "")
# Identifying families with small sizes
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
# Data cleaning - some small families slipped through the net
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2, ]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
# Resplitting the training and test datasets
train <- combi[1:891, ]
test <- combi[892:1309, ]
summary(combi$Age)
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
summary(combi$Age)
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
summary(combi$Age)
printcp(Agefit)
?rpart
sum(predict(Agefit, type="class")!=car$V7)/nrow(car)
?printcp
summary(combi)
combi$Embarked[which(combi$Embarked == '')] = "S"
combi$Embarked[which(combi$Embarked == '')] = "S"
combi$Fare[which(is.na(combi$Fare))] <- median(combi$Fare, na.rm=TRUE)
combi$Embarked[which(combi$Embarked == '')] = "S"
combi$Fare[which(is.na(combi$Fare))] <- median(combi$Fare, na.rm=TRUE)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
install.packages('randomForest')
library(randomForest)
set.seed(415)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize +
FamilyID2, data=train, importance=TRUE, ntree=2000)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
set.seed(415)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize +
FamilyID2, data=train, importance=TRUE, ntree=2000)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2, data=train, importance=TRUE, ntree=2000)
train <- combi[1:891, ]
test <- combi[892:1309, ]
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID2, data=train, importance=TRUE, ntree=2000)
varImpPlot(fit)
Prediction <- predict(fit, test)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "firstforest.csv", row.names = FALSE)
